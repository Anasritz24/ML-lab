{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anasritz24/ML-lab/blob/main/problem8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Write a program to demonstrate the working of the decision tree based ID3 algorithm.Use an appropriate data set for building the decision tree and apply this knowledge to classify a new sample."
      ],
      "metadata": {
        "id": "xCRVX_KnVkAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rzddnRvgZq2v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the dataset and define the feature as well as the target datasets/columns\n",
        "\n",
        "dataset=pd.read_csv('playtennis.csv',names=['outlook','temperature', 'humidity','wind', 'class'])\n",
        "\n",
        "#Import all columns omitting the fist which consists the names of the animals\n",
        "attributes=('Outlook','Temperature','Humidity', 'Wind', 'PlayTennis')\n",
        "def entropy(target_col):\n",
        "    \"\"\"Calculatetheentropyofadataset.\n",
        "       Theonlyparameterofthisfunctionisthetarget_colparameterwhich\n",
        "       specifiesthetargetcolumn\"\"\"\n",
        "\n",
        "    elements,counts=np.unique(target_col,return_counts=True)\n",
        "    if len(elements) <= 1:\n",
        "        print('Entropy=', 0)\n",
        "        return 0\n",
        "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts))\n",
        "  for i in range(len(elements))])\n",
        "    print('Entropy=',entropy)\n",
        "    return entropy\n",
        "#Calculate the entropy of the dataset\n",
        "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
        "  total_entropy=entropy(data[target_name])"
      ],
      "metadata": {
        "id": "IybNjS1zZ6Vh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8058ed0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1337f8-566a-4b22-fc67-3cd63f8c1e5d"
      },
      "source": [
        "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
        "    #Calculate the total entropy of the target variable\n",
        "    total_entropy = entropy(data[target_name])\n",
        "\n",
        "    #Calculate the values and the corresponding counts for the split attribute\n",
        "    vals,counts=np.unique(data[split_attribute_name],return_counts=True)\n",
        "\n",
        "    #Calculate the weighted entropy\n",
        "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*(entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name])) for i in range(len(vals))])\n",
        "\n",
        "    #Calculate the information gain\n",
        "    Information_Gain = total_entropy - Weighted_Entropy\n",
        "    return Information_Gain\n",
        "\n",
        "def ID3(data, originaldata, features, target_attribute_name=\"class\", parent_node_class=None):\n",
        "  if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "    return np.unique(data[target_attribute_name])[0]\n",
        "\n",
        "  elif len(data) == 0:\n",
        "    return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
        "\n",
        "  elif len(features) == 0:\n",
        "    return parent_node_class\n",
        "\n",
        "  else:\n",
        "    parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
        "\n",
        "    #Select the feature which best splits the dataset\n",
        "\n",
        "    item_values = [InfoGain(data,feature,target_attribute_name) for feature in features]\n",
        "    best_feature_index = np.argmax(item_values)\n",
        "    best_feature = features[best_feature_index]\n",
        "\n",
        "    #Cteate the tree structure\n",
        "    tree = {best_feature:{}}\n",
        "\n",
        "    features = [i for i in features if i != best_feature]\n",
        "\n",
        "    for value in np.unique(data[best_feature]):\n",
        "      value = value\n",
        "\n",
        "      #Split the dataset along the value of the feature with the largest information gain\n",
        "      sub_data = data.where(data[best_feature] == value).dropna()\n",
        "\n",
        "      subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
        "\n",
        "      tree[best_feature][value] = subtree\n",
        "\n",
        "    return(tree)\n",
        "\n",
        "def predict(query,tree,default=1):\n",
        "  for key in list(query.keys()):\n",
        "    if key in list(tree.keys()):\n",
        "      try:\n",
        "        result = tree[key][query[key]]\n",
        "      except:\n",
        "        return default\n",
        "      if isinstance(result, dict):\n",
        "        return predict(query, result)\n",
        "      else:\n",
        "        return result\n",
        "\n",
        "def test(data,tree):\n",
        "  queries = data.iloc[:,:-1].to_dict(orient=\"records\")\n",
        "  predicted = pd.DataFrame(columns=[\"predicted\"])\n",
        "\n",
        "  #Calculate the prediction accuracy\n",
        "  for i in range(len(data)):\n",
        "    predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0)\n",
        "\n",
        "  print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data[\"class\"])/len(data))*100,'%')\n",
        "\n",
        "def train_test_split(dataset):\n",
        "  # For simplicity, we'll use the whole dataset for training and testing\n",
        "  return dataset\n",
        "\n",
        "#Train the three,Print the tree and predict the Accuracy\n",
        "\n",
        "training_data = train_test_split(dataset)\n",
        "tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
        "print('Display Tree:\\n', tree)\n",
        "print('len=:;',len(training_data))\n",
        "test(training_data,tree)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entropy= 1.1660870601063933\n",
            "Entropy= 1.0\n",
            "Entropy= 0\n",
            "Entropy= 0.9709505944546686\n",
            "Entropy= 0\n",
            "Entropy= 1.1660870601063933\n",
            "Entropy= 1.0\n",
            "Entropy= 0.8112781244591328\n",
            "Entropy= 0.8112781244591328\n",
            "Entropy= 0\n",
            "Entropy= 1.1660870601063933\n",
            "Entropy= 0.9852281360342515\n",
            "Entropy= 0.5032583347756457\n",
            "Entropy= 0\n",
            "Entropy= 1.1660870601063933\n",
            "Entropy= 0.8112781244591328\n",
            "Entropy= 0.954434002924965\n",
            "Entropy= 0\n",
            "Entropy= 1.0\n",
            "Entropy= 0\n",
            "Entropy= 0.9182958340544896\n",
            "Entropy= 0\n",
            "Entropy= 1.0\n",
            "Entropy= 0\n",
            "Entropy= 0\n",
            "Entropy= 1.0\n",
            "Entropy= 0.9182958340544896\n",
            "Entropy= 0.9182958340544896\n",
            "Entropy= 0.9709505944546686\n",
            "Entropy= 0.9182958340544896\n",
            "Entropy= 1.0\n",
            "Entropy= 0.9709505944546686\n",
            "Entropy= 1.0\n",
            "Entropy= 0.9182958340544896\n",
            "Entropy= 0.9709505944546686\n",
            "Entropy= 0\n",
            "Entropy= 0\n",
            "Display Tree:\n",
            " {'outlook': {'0': {'humidity': {'0': '0', '1': '1'}}, '1': '1', '2': {'wind': {'0': '1', '1': '0'}}, 'Outlook': 'PlayTennis'}}\n",
            "len=:; 17\n",
            "The prediction accuracy is:  100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "n1KJ2DbzdHDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}